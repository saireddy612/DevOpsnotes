*Importance of Container Orchestration:
It does so many tasks , some of them
1. provisioning and deployment of container among the virtual machinces is not automated, if we want to distribute 100s of 
containers among VM's, it is very difficult to deploy manually. Hence, Container Orchestration tool make it easier to control 
over it.
2. Scaling up & down, removing container in order to spread the application load evenly.
3. It can controll the movement of containers from one VM's to another VM's due to lack of resources in the VM.

Container Orchestration solutions:
1.Docker Swarm
2.kubernetes
3.Openshift
4.Apache Mesos

platforms:
EKS: Elastic Kubernetes service(paid)
GKE: Google Kubernetes Engine(paid, free-90days)
AKE: Azure kubernetes Engine(paid)

Container Orchestration Tools:                                                                    Orchetration=Management
1.Replicas
2.Distribution
3.Cluster mode
4.Scale up & down
5. High availability
6. Rolling update

Diff between Docker Swarm & Kubernetes:
|------------------------------------------------------------------|--------------------------------------------------------------|
|                    Docker                                        |                    Kubernetes                                |
|------------------------------------------------------------------|--------------------------------------------------------------|
|> It can Orchestrate docker container only, container runtim      |> It can Orchestrate containers of other tols also, It has se-|
|  is always docker                                                |perate container runtime interface and we will seee kubernetes|                           | 
|                                                                  |is always used with docker                                    |
|------------------------------------------------------------------|--------------------------------------------------------------|
|>Manager node and worker node(multiple manager is possi)          |> Master and worker node (only one master node)               |
|------------------------------------------------------------------|--------------------------------------------------------------|
|>Containers are scheduled on manager as well as working node      |> Containers are by default scheduled on worker node          |
|------------------------------------------------------------------|--------------------------------------------------------------|
|>RAFT algorithm is responsible to conduct the orchestration activi|>various objects and controllers are respon for orch activi   |
|------------------------------------------------------------------|--------------------------------------------------------------|
|>There is no auto scaling                                         |>supports auto scaling with help of Horizontal pod autoscaler |
|------------------------------------------------------------------|--------------------------------------------------------------|
|>Single Line Commands                                             |>we can write object definition/manifest files -YAML          |
|------------------------------------------------------------------|--------------------------------------------------------------|
|>There is no free dashboard to display the service objects        |>It has dashboard to display all its objects and its manifest |
|------------------------------------------------------------------|--------------------------------------------------------------|
|>In docker swarm, data of container sis preserved on vm itself    |>It can preserve data of container outside the cluster        |
|                                                                  | like PV:persistent volume, PVC: persistent volume claim      |
|------------------------------------------------------------------|--------------------------------------------------------------|

Docker tool:
It is basically tool which uses the dockerhub images and converts into the container in a single VM.
Kubernetes tool:
It uses the Docker for collecting the image and will create a Multiple containers in multiple  VMs based upon the available resources on 
each VMs.
Docker swarm:
It does the same to kubernetes except some fucntionalities like autoscaling, YAML, Single Line Command.
                                 
                                                                        Master
                       |-------------------------------------------------------------------------------------------------------------|
                       |1. Apiserver: principle component, will recieve requests from kubectl to create containers                   |
                       |2. Schedular: it will trac the container. It will decide and tell to Apiserver where to create containers    |
                       |3. ETCD:It has complete information about the cluster like IP address etc.,                                  |
                       |4. Controller Manager: deploy,scaling up & down will manage
                       |
                       |-------------------------------------------------------------------------------------------------------------|
                       
                                    worker node-1                                            worker node-2
                       |--------------------------------------------------------|  |-------------------------------------------------|
                       |kubelet:                                                |  |kubelet,kubeproxy                                |
                       |Apiserver will send request kubelet to create particular|  |                                                 |
                       |number of containers.                                   |  |                                                 |
                       |kubelet will pull image from docker                     |  |                                                 |
                       |kubeproxy:                                              |  |                                                 |
                       |it will gives set of network rules, using this user     |  |                                                 |
                       |can access data                                         |  |                                                 |
                       |--------------------------------------------------------|  |-------------------------------------------------|

> kubectl command will sends the request to apiserver to create containers, apiserver will ask schedular about where to schedule container
 schedular will get the information from ETCD which has information about the availability of resources,Apiserver will talk to kubelet 
 inorder to pull image. After this Apiserver will update about the containers(pod). Now the Controller manager duty is to manage the desired
 number of replicas to be running. Kubeproxy will allows port mapping to acces the containers, two containers can talk using the kubeproxy.

> Initally create a cloud.console account with card

POD: its a smallest deployable unit in kubernetes. it is basically an abstract of container, In kubernetes we won't create container directly,
instead we look upon the POD. Multiple pods with same container is possible(ex: create a pods of nginx image). Each pod can have multiple
containers that dependent on each other.

NODE: VM's in the cluster where docker and kubernete is installed.
Replica: same pods with same container and image.

YAML:
>it is not a programming or scripting language.
>It is just a format to store data, like json, xml files
>It's very easy to read and write
>It's declarative in nature.
>Indentation(spacing) is important.
>In kubernetes the key is provided by the tool itself
>Value is written by user
>In the key we can have single value and multiple value.

Syntax:
key: value

YAML format to save single value:
trainer: Sai
training: devops
time: 8.30PM IST
day: weekday                                                                     [YAMLLINT its a website, where we can validate the yaml]

Create a pod in kubernetes:

apiVersion: v1
kind: Pod
metadata:
  name: pod1
  labels:
    author: sonal
    env: dev
    app: webserver
spec:
 containers:
  - name: c1
    image: nginx

YAML format to save multiple values:
company: Edureka
trainer:           |go to next line and two spaces and write values)
  -Sonal
  -Ravi
  -John
  -Jaya
trainings:
  -Devops
  -AWS
  -AZURE
  -GCP
timings:
  -8.30PM
  
YAML format to save multiple values as a Map(key: value)
company: polo
Trainers:
  -name: Sonal
   phone: 75895
   email: 999898
  -name: Sai
   phone: slsls
   email: lslsl
tainings:
  -type: cloud
   name:
 |-----------------------------------------|
 |   kubectl get nodes                     |
 |  kubectl get nodes -o wide              |
 |  mkdir 23May                            |
 |  cd 23May                               |
 |  vim pod-definition.yml                 |
 |  kubectl create -f pod-definition.yml   |
 |  vim pod-definition.yml                 |
 |  kubectl create -f pod-definition.yml   |
 |  ls                                     |
 |  kubectl get pods                       |
 |  kubectl get pod -o wide                |
 |  kubectl describe pod | less            |
 |-----------------------------------------|
 > Each pod consist of multiple containers with single port deatils and containers in a pod will share the pod 
 IP port deatis but when multiple containers in a pods shares the IP details it will leads to backoff error.
 hence, we need to find which containers causing the problems with looking at log details.
 apiversion: v1 it is a pod library
 metadata: consist of label, names and all
 selector: before creating replica, it will run the query

|------------------------------------------------------------------|----------------------------------------------------------------|
|kubectl get nodes                                                 | It will list the details of nodes                              |
|------------------------------------------------------------------|----------------------------------------------------------------|
|kubectl get pods                                                  | It will list the details of nodes                              |
|------------------------------------------------------------------|----------------------------------------------------------------|
|kubectl get pod -o wide                                           | It will give full details about pods                           |
|------------------------------------------------------------------|----------------------------------------------------------------|
|kubectl create -f file.yml                                        | It will create a pod                                           |
|------------------------------------------------------------------|----------------------------------------------------------------|
|kubectl delete pod pod1                                           |Deleting a pod                                                  |
|------------------------------------------------------------------|----------------------------------------------------------------|
|kubectl delete pods --all                                         |Deleting all pod                                                |
|------------------------------------------------------------------|----------------------------------------------------------------|
|kubectl describe pod | less                                       | It will describe the pod details                               |
|------------------------------------------------------------------|----------------------------------------------------------------|
|kubectl delete rs replicasname                                    | Deleting replicas                                              |
|------------------------------------------------------------------|----------------------------------------------------------------|
|kubectl delete replicaset --all                                   | Deleting all replicas                                          |
|------------------------------------------------------------------|----------------------------------------------------------------|
|kubectl exec -it podname -- bash                                  | to enter into the pod,podname get kubectl get all cmnd         |
|------------------------------------------------------------------|----------------------------------------------------------------|
|kubectl get pods --show-labels                                    | shows the labels of the pods                                   |
|------------------------------------------------------------------|----------------------------------------------------------------|
|apt-get update && apt-get install curl -y                         | creating curl                                                  |
|------------------------------------------------------------------|----------------------------------------------------------------|
|kubectl describe service servicename                              | Describes the full details of a service                        |
|------------------------------------------------------------------|----------------------------------------------------------------|
|curl serviceIPaddress                                             | to access the pod data by user using nodeport service object,  |
|                                                                  |we should be inside the nodeport service, IP will kubectlgetall |
|------------------------------------------------------------------|----------------------------------------------------------------|
|kubectl create -f website                                         | using website we can create replicas or pods                   |
|------------------------------------------------------------------|----------------------------------------------------------------|
|kubectl get deployment nameofreplicawithserver -o wide            | It will create and deploy the replica with nopeport serviceobjt|
|------------------------------------------------------------------|----------------------------------------------------------------|
|kubectl set image deployment naofrepliser app=kubeservename:v2    |It will update a new image using the replica's yml filename.    |
|------------------------------------------------------------------|----------------------------------------------------------------|
|kubectl rollout undo deployment nameofreplicawithserver           | It will go back to the old version of replica                  |
|------------------------------------------------------------------|----------------------------------------------------------------|
|kubectl rollout history deployment nameofreplicawithserver        | shows the versions history                                     |
|------------------------------------------------------------------|----------------------------------------------------------------|
|kubectl delete all --all                                          | To delete all the contents irrespectively                      |
|------------------------------------------------------------------|----------------------------------------------------------------|
|



ReplicaSet- Controller:
This object is used to create a multiple pods which are same/replicas.
specifications:
>How many replicas/pods(having same container-duplicates)
>What container should be on the POD
Replicaset yml code example:

kind: ReplicaSet
apiVersion: apps/v1
metadata:
 name: myrs
spec:
 replicas: 3 # desired number of PODs
 selector: # query to select pods with matching labels
  matchLabels:
   type: webserver
 template: #heretemplate is Pod template,i.e.what should be on the POD,you are writing Pod details
  metadata:
   labels: # here labels is key and value given by user to group similar pods
    type: webserver
    app: java
    author: sonal
  spec: # this is pod specification
   containers:
    - name: c1
      image: nginx
      
Service Object: Port Mapping
Service object basically provides the communication between the user and pods and it is helpful for portmapping.
It consists of two types 1. Nodeport, 2. ClusterIP.
1. Nodeport:
   It allows user to connect with the pods via browser using port address, and it has range of 30000-37676
2. ClusterIP:
   It allows to exchange or to process the communication between pods. It is a default service object run by 
   kubernetes with constant port number.
   
Let's see with a scenario:
An an enduser wants to connect with a pod1. He can contact the pod1 through frontend app which is basically a pod.
endsuer could communicate with frontend app using the Nodeport. Now, the nodeport will contact the pod1. In worst
cases pod1 get deleted and kubernetes prompty creates the pod1 but the conflict is the IP address of pod1 changed 
now. Since, the frontend app connected pod1 through the deleted pod1 IP address. In order to overcome this issue
ClusterIP came into picture i.e. static IP address and port number.

Example for creating a service object for ClusterIP type:

apiVersion: v1
kind: Service
metadata:
  name: myservice1
spec:
  type: ClusterIP
  selector:
    type: webserver
  ports:
    - targetPort: 80
      port: 80
Example for creating a service object for Nodeport type:

apiVersion: v1
kind: Pod
metadata:
  name: testpod
spec:
  containers:
    - name: c1
      image: ubuntu
      command: ["bash", "-c", "sleep 6000"]
*Deployment Object:
> Used to create a Replicas
> Maintains the Rolling update and Rollback feature.

Let's see a scenarion:
A replica with 3 pods got created with a version app:v1. Now, the operator wants to update the one of the images in the
pod, he/she can not go and update the pod directly, instead a new replicaset get created with a new version of
app:v2 with deleted the old replica's pods individually. If we don't want the new image, we can rollback to the original
version to v1.

combination of creating replicas and nodeport service example for deployment:

kind: Deployment
apiVersion: apps/v1
metadata:
  name: kubeserve
spec:
  replicas: 3
  minReadySeconds: 10 # wait for 45 sec before going to deploy next pod
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1  
      maxSurge: 1        # max number of pods to run for the deployment
  selector:
    matchLabels:
      app: kubeserve
  template:
    metadata:
      name: kubeserve
      labels:
        app: kubeserve
    spec:
      containers:
       - name: app
         image: leaddevops/kubeserve:v1
        
---
kind: Service
apiVersion: v1
metadata:
   name: kubeserve-svc
spec:
  type: NodePort
  ports:
    - port: 80
      targetPort: 80
  selector: 
    app: kubeserve



VOLUMES:
 Generally, the container details going to store physically on the working laptop or machine, if the machine is going
 to crash then, there is a chance to lose data. Hence, we need to preserve the data using volume concept. This storage
 of volume could get by raising a ticket to IT Team as I need 30Gb or 50 Gb of storage for my project. Based on the 
 available resources IT Team will allow the storage.
 When it comes to kubernetes, it consists of multiple replicas and pods with containers. Now, storage admins will create
 or configure the storage drivers (google, Azure etc.,) volumes[NFS, glusterfs, persistent Disk, local hostpath]
 kubernetes admin should define the type of volume,capacity,location,access. ex: persistent volume object. Since, the pod cann't
 store the data into the volume directly, it will use the help of Persistent Volume Claim object by raising the ticker
 that grant a pod access to a Persistent Volume.
 
 
 POD--------------------> persistentVolumeClaim----------------> persistentVolume
 (mountpoint)(GCP)
 
 Access Mode:
 what kind of access do we have to the volume:
 READ WRITE Once:
 volume get created on a particular node and the pods on that node will use the volume within the node.
 *hostpath:
   path: /tmp/data
 READ WRITE MANY
 READ ONLY MANY
 
 Namespace:
 >It is used to mention a pod with specific name details which will help to recognize while performing delete action.
 >It will be given in the yml file, metadata.
 
 CONTINOUS MONITORING:
 > Prometheus: opensource tool
 Architecture:
 1. Retrieval
 2. Storage
 3. HTP Server
 4. Prometheus (Web GUI)
 5. Alert Manager
 Operation: The retrieval take the metric data(Counter, Histogram, Gauges, Summary) from the kubernetes and based on the time stand Storage will stores the
 data, HTTP server will provides the dta to the user from Storage.
 Graphana
 


 
  
   











































